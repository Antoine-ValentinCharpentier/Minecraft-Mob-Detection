{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - Prepare the dataset\n",
    "In this section, we will reorganize our dataset. \n",
    "\n",
    "Thus, we will move the images contained directly in the test, train, and valid folders into subfolders (hostile, passive) based on the nature of the creatures present in the respective image. \n",
    "\n",
    "The nature of each creature present in the image can be obtained from the _annotations.csv files present in each folder of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_images_dataset(path_folder):\n",
    "    \"\"\"\n",
    "    Sorts images in a dataset based on their class, moving them to separate folders.\n",
    "    If the image represents a passive creature, it will be moved to the 'passive' subfolder, otherwise, it will be moved to the 'hostile' subfolder.\n",
    "\n",
    "    Parameters:\n",
    "        - path_folder (str): Path to the folder containing the images and _annotations.csv file.\n",
    "\n",
    "    \"\"\"\n",
    "    PASSIVE_CLASS_LIST = ['chicken', 'cow', 'pig', 'sheep', 'bee', 'fox', 'frog', 'goat', 'llama', 'turtle', 'wolf']\n",
    "    annotations_path = os.path.join(path_folder, '_annotations.csv')\n",
    "    annotations_data = pd.read_csv(annotations_path)\n",
    "    \n",
    "    for filename, classe in annotations_data[['filename', 'class']].values:\n",
    "\n",
    "        img_path = os.path.join(path_folder, filename)\n",
    "        if os.path.exists(img_path):\n",
    "\n",
    "            category = \"hostile\" if classe in PASSIVE_CLASS_LIST else \"passive\"\n",
    "            category_dir = os.path.join(path_folder, category)\n",
    "\n",
    "            if not os.path.exists(category_dir):\n",
    "                os.makedirs(category_dir)\n",
    "            \n",
    "            new_img_path = os.path.join(category_dir, filename)\n",
    "            os.rename(img_path, new_img_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_to_sort = ['./data/train', './data/test', './data/valid']\n",
    "for path in path_dataset_to_sort:\n",
    "    sort_images_dataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preprocessing\n",
    "\n",
    "> How are we going to preprocess our images? \n",
    "\n",
    "Actually, we are going to do multiple things. We will apply various transformations to all images in the training set. However, we will not apply the same transformations to the test set. The reason is to prevent overfitting. If we fail to apply these transformations properly during training on the training set, we will observe a significant difference in accuracy between the training and test sets. The accuracy on the training set will be very high, whereas it will be much lower on the test set.\n",
    "\n",
    "In the realm of computer vision, the key to avoiding overfitting is to apply certain transformations.\n",
    "\n",
    "> What do these transformations consist in ? \n",
    "\n",
    "They encompass simple geometrical transformations, zooms, rotations on our images, and more. This process is called image augmentation. The aim is to prevent the CNN from overlearning on the existing images. By applying these transformations, we generate new images, thereby increasing the variety and diversity of our dataset.\n",
    "\n",
    "\n",
    "\n",
    "### Preprocessing the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255, # Normalisation / Feature scaling\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2307 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "                        './data/train',\n",
    "                        target_size=(64, 64), # final size of images\n",
    "                        batch_size=32,\n",
    "                        class_mode='binary'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 155 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "                './data/test',\n",
    "                target_size=(64, 64),\n",
    "                batch_size=32,\n",
    "                class_mode='binary'\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
